{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import csv\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETAPE 1 : DUPLICATION DES NOTICES ISAD INDEXEES AVEC PLUSIEURS NOMS ET SUPPRESSION DES NOTICES NON INDEXEES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'csv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 55\u001b[0m\n\u001b[1;32m     45\u001b[0m column_mapping \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mISAD_title\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscopeAndContent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mISAD_scopeAndContent\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreferenceCode\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mISAD_cote\u001b[39m\u001b[38;5;124m\"\u001b[39m      \n\u001b[1;32m     52\u001b[0m }\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# APPEL DE LA FONCTION\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m \u001b[43mprocess_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_csv_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_csv_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselected_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_mapping\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m, in \u001b[0;36mprocess_csv\u001b[0;34m(input_csv_file, output_csv_file, selected_columns, column_mapping)\u001b[0m\n\u001b[1;32m      2\u001b[0m new_data \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(input_csv_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m----> 4\u001b[0m     reader \u001b[38;5;241m=\u001b[39m \u001b[43mcsv\u001b[49m\u001b[38;5;241m.\u001b[39mDictReader(file)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m reader:\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;66;03m# Si la colonne 'nameAccessPoints' contient des données multiples\u001b[39;00m\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnameAccessPoints\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m      8\u001b[0m             \u001b[38;5;66;03m# Traite les données multiples et ajoute les nouvelles lignes à la liste des nouvelles données\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'csv' is not defined"
     ]
    }
   ],
   "source": [
    "def process_csv(input_csv_file, output_csv_file, selected_columns, column_mapping):\n",
    "    new_data = []\n",
    "    with open(input_csv_file, 'r', encoding='utf-8') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            # Si la colonne 'nameAccessPoints' contient des données multiples\n",
    "            if \"|\" in row[\"nameAccessPoints\"]:\n",
    "                # Traite les données multiples et ajoute les nouvelles lignes à la liste des nouvelles données\n",
    "                new_data.extend(process_name(row, selected_columns, column_mapping))\n",
    "            # Sinon, si la colonne 'nameAccessPoints' n'est pas vide\n",
    "            elif row[\"nameAccessPoints\"].strip() != \"\":\n",
    "                # Ajoute une nouvelle ligne avec les colonnes sélectionnées à la liste des nouvelles données\n",
    "                new_data.append({column_mapping.get(key, key): row.get(key, \"\") for key in selected_columns})\n",
    "    write_csv(output_csv_file, new_data, [column_mapping.get(col, col) for col in selected_columns])\n",
    "\n",
    "def process_name(row, selected_columns, column_mapping):\n",
    "    # Divise les données multiples séparées par '|' dans la colonne 'nameAccessPoints'\n",
    "    names = row[\"nameAccessPoints\"].split(\"|\")\n",
    "    new_rows = []\n",
    "    # Pour chaque nom séparé, crée une nouvelle ligne avec les colonnes sélectionnées\n",
    "    for name in names:\n",
    "        # Crée un nouveau dictionnaire avec les colonnes sélectionnées\n",
    "        new_row = {column_mapping.get(key, key): row.get(key, \"\") for key in selected_columns}\n",
    "        # Ajoute le nom actuel à la nouvelle ligne\n",
    "        new_row[column_mapping.get(\"nameAccessPoints\", \"nameAccessPoints\")] = name\n",
    "        new_rows.append(new_row)\n",
    "    return new_rows\n",
    "\n",
    "def write_csv(output_csv_file, data, selected_columns):\n",
    "    with open(output_csv_file, 'w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=selected_columns)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data)\n",
    "    print(\"Fichier csv contenant uniquement les noms indexés dans\", output_csv_file)\n",
    "    \n",
    "# LANCEMENT\n",
    "# Chemins vers les fichiers csv\n",
    "input_csv_file = \"01_isad_data.csv\"\n",
    "output_csv_file = \"03_isad_data_OUTPUT.csv\"\n",
    "\n",
    "# Liste des colonnes à conserver\n",
    "selected_columns = [\"nameAccessPoints\", \"title\", \"scopeAndContent\", \"eventDates\", \"eventStartDates\", \"eventEndDates\", \"referenceCode\"]\n",
    "\n",
    "# Dictionnaire de mappage des intitulés de colonnes\n",
    "column_mapping = {\n",
    "        \"title\": \"ISAD_title\",\n",
    "        \"scopeAndContent\": \"ISAD_scopeAndContent\",\n",
    "        \"eventDates\": \"ISAD_eventDates\",\n",
    "        \"eventStartDates\" : \"ISAD_eventStartDates\",\n",
    "        \"eventEndDates\":\"ISAD_eventEndDates\",\n",
    "        \"referenceCode\":\"ISAD_cote\"      \n",
    "}\n",
    "\n",
    "# APPEL DE LA FONCTION\n",
    "process_csv(input_csv_file, output_csv_file, selected_columns, column_mapping)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETAPE 2 : RECUPERER LES NOUVELLES AUTORITES (false) ET EXTRAIRE CES NOMS AVEC LEUR INFORMATIONS DU FICHIER CSV 03_isad_data_OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'csv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 56\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAucun nom correspondant trouvé.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m#LANCEMENT\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m false_autorites \u001b[38;5;241m=\u001b[39m \u001b[43mextract_false_rows\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m02_CLSR_Correspondance.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFound\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m new_autorities \u001b[38;5;241m=\u001b[39m compare_names_with_initial(initial_csv_file, false_autorites)\n\u001b[1;32m     58\u001b[0m write_new_authorities_to_csv(output_csv_file, new_autorities)\n",
      "Cell \u001b[0;32mIn[3], line 16\u001b[0m, in \u001b[0;36mextract_false_rows\u001b[0;34m(csv_file, column_name)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Lecture du fichier CSV\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(csv_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m---> 16\u001b[0m     reader \u001b[38;5;241m=\u001b[39m \u001b[43mcsv\u001b[49m\u001b[38;5;241m.\u001b[39mDictReader(file)\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# Parcours de chaque ligne\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m reader:\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;66;03m# Vérification si la valeur dans la colonne spécifiée est False\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'csv' is not defined"
     ]
    }
   ],
   "source": [
    "# Chemin vers le fichier CSV contenant les données initiales\n",
    "initial_csv_file = \"03_isad_data_OUTPUT.csv\"\n",
    "\n",
    "# Obtenez la date actuelle\n",
    "current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Créer le nom du fichier CSV de sortie avec la date\n",
    "output_csv_file = f\"04_PHOEBUS_NEW_AUTHORITY_{current_date}.csv\"\n",
    "\n",
    "# Fonction pour extraire les lignes avec la valeur False dans une colonne donnée\n",
    "def extract_false_rows(csv_file, column_name):\n",
    "    false_autorites = []\n",
    "\n",
    "    # Lecture du fichier CSV\n",
    "    with open(csv_file, 'r', encoding='utf-8') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        # Parcours de chaque ligne\n",
    "        for row in reader:\n",
    "            # Vérification si la valeur dans la colonne spécifiée est False\n",
    "            if row[column_name].strip() == \"[False]\":\n",
    "                # Suppression littérale des séquences [' et ']\n",
    "                autorite = row[\"Autorites\"].replace(\"['\", \"\").replace(\"']\", \"\")\n",
    "                false_autorites.append(autorite)\n",
    "\n",
    "    return false_autorites\n",
    "\n",
    "# Fonction pour comparer les noms extraits avec la colonne \"nameAccessPoints\" du fichier initial\n",
    "def compare_names_with_initial(csv_file, names_to_compare):\n",
    "    new_autorities = []\n",
    "\n",
    "    # Lecture du fichier CSV initial\n",
    "    with open(csv_file, 'r', encoding='utf-8') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        # Parcours de chaque ligne\n",
    "        for row in reader:\n",
    "            # Vérification si le nom extrait se trouve dans la colonne \"nameAccessPoints\"\n",
    "            if row[\"nameAccessPoints\"] in names_to_compare:\n",
    "                # Ajout de la colonne supplémentaire Statut indiquant si c'est une nouvelles notices ou non\n",
    "                row[\"Statut\"] = \"NEW AUTHORITY\"\n",
    "                new_autorities.append(row)\n",
    "\n",
    "    return new_autorities\n",
    "\n",
    "def write_new_authorities_to_csv(output_csv_file, new_autorities):\n",
    "    with open(output_csv_file, 'w', newline='', encoding='utf-8') as file:\n",
    "        if new_autorities:\n",
    "            writer = csv.DictWriter(file, fieldnames=new_autorities[0].keys())\n",
    "            writer.writeheader()\n",
    "            writer.writerows(new_autorities)\n",
    "            print(\"Les nouvelles autorités ont été écrites dans\", output_csv_file)\n",
    "        else:\n",
    "            print(\"Aucun nom correspondant trouvé.\")\n",
    "\n",
    "\n",
    "#LANCEMENT\n",
    "false_autorites = extract_false_rows(\"02_CLSR_Correspondance.csv\", \"Found\")\n",
    "new_autorities = compare_names_with_initial(initial_csv_file, false_autorites)\n",
    "write_new_authorities_to_csv(output_csv_file, new_autorities)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETAPE 3 : RECUPERER LES ANCIENNES AUTORITES (true) ET EXTRAIRE CES NOMS AVEC LEUR INFORMATIONS DU FICHIER CSV 03_isad_data_OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les anciennes autorités ont été écrites dans 04_PHOEBUS_OLD_AUTHORITY_2024-05-27.csv\n"
     ]
    }
   ],
   "source": [
    "# Fonction pour extraire les lignes avec la valeur True dans une colonne donnée\n",
    "def extract_true_rows(csv_file, column_name):\n",
    "    true_autorites = []\n",
    "\n",
    "    # Lecture du fichier CSV\n",
    "    with open(csv_file, 'r', encoding='utf-8') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        # Parcours de chaque ligne\n",
    "        for row in reader:\n",
    "            # Vérification si la valeur dans la colonne spécifiée est True\n",
    "            if row[column_name].strip() == \"[True]\":\n",
    "                # Suppression littérale des séquences [' et ']\n",
    "                autorite = row[\"Autorites\"].replace(\"['\", \"\").replace(\"']\", \"\")\n",
    "                true_autorites.append(autorite)\n",
    "\n",
    "    return true_autorites\n",
    "\n",
    "# Fonction pour comparer les noms extraits avec la colonne \"nameAccessPoints\" du fichier initial\n",
    "def compare_names_with_initial(csv_file, names_to_compare):\n",
    "    old_autorities = []\n",
    "\n",
    "    # Lecture du fichier CSV initial\n",
    "    with open(csv_file, 'r', encoding='utf-8') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        # Parcours de chaque ligne\n",
    "        for row in reader:\n",
    "            # Vérification si le nom extrait se trouve dans les noms à comparer\n",
    "            if row[\"nameAccessPoints\"] in names_to_compare:\n",
    "                # Ajout de la colonne supplémentaire Statut indiquant si c'est une ancienne notice ou non\n",
    "                row[\"Statut\"] = \"OLD AUTHORITY\"\n",
    "                old_autorities.append(row)\n",
    "\n",
    "    return old_autorities\n",
    "\n",
    "def write_old_authorities_to_csv(output_csv_file_old, old_autorities):\n",
    "    with open(output_csv_file_old, 'w', newline='', encoding='utf-8') as file:\n",
    "        if old_autorities:\n",
    "            writer = csv.DictWriter(file, fieldnames=old_autorities[0].keys())\n",
    "            writer.writeheader()\n",
    "            writer.writerows(old_autorities)\n",
    "            print(\"Les anciennes autorités ont été écrites dans\", output_csv_file_old)\n",
    "        else:\n",
    "            print(\"Aucune ancienne autorité trouvée.\")\n",
    "\n",
    "\n",
    "#LANCEMENT\n",
    "output_csv_file_old = f\"04_PHOEBUS_OLD_AUTHORITY_{current_date}.csv\"\n",
    "true_autorites = extract_true_rows(\"02_CLSR_Correspondance.csv\", \"Found\")\n",
    "old_autorities = compare_names_with_initial(initial_csv_file, true_autorites)\n",
    "write_old_authorities_to_csv(output_csv_file_old, old_autorities)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APPELS DES FONCTIONS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les données ont été écrites dans 04_PHOEBUS_NEW_AUTHORITY_2024-05-27.csv\n",
      "Aucun nom correspondant trouvé.\n",
      "Les anciennes autorités ont été écrites dans 04_PHOEBUS_OLD_AUTHORITY_2024-05-27.csv\n"
     ]
    }
   ],
   "source": [
    "# ETAPE 1\n",
    "process_csv(input_csv_file, output_csv_file, selected_columns, column_mapping)\n",
    "\n",
    "# ETAPE 2\n",
    "false_autorites = extract_false_rows(\"02_CLSR_Correspondance.csv\", \"Found\")\n",
    "new_autorities = compare_names_with_initial(initial_csv_file, false_autorites)\n",
    "write_new_authorities_to_csv(output_csv_file, new_autorities)\n",
    "\n",
    "# ETAPE 3\n",
    "output_csv_file_old = f\"04_PHOEBUS_OLD_AUTHORITY_{current_date}.csv\"\n",
    "true_autorites = extract_true_rows(\"02_CLSR_Correspondance.csv\", \"Found\")\n",
    "old_autorities = compare_names_with_initial(initial_csv_file, true_autorites)\n",
    "write_old_authorities_to_csv(output_csv_file_old, old_autorities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
