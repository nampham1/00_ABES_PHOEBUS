{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "import urllib\n",
    "import webbrowser\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"\"\"\n",
    "    En-têtes HTTP couramment utilisés pour simuler une requête HTTP provenant d'un navigateur. Ces en-têtes peuvent être ajustés en fonction des besoins spécifiques de la requête.\n",
    "\n",
    "    - 'User-Agent': Identifie le type de navigateur et le système d'exploitation utilisé.\n",
    "    - 'Accept': Indique les types de contenu que le client peut traiter.\n",
    "    - 'Accept-Language': Spécifie les langues préférées pour la réponse.\n",
    "    - 'Connection': Contrôle si la connexion réseau doit être maintenue ou non après la transaction courante.\n",
    "    \"\"\"\n",
    "    \n",
    "    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 14_1_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=1.0,image/webp,image/apng,*/*;q=0.8',\n",
    "    'Accept-Language': 'fr;q=0.9',\n",
    "    'Connection': 'keep-alive',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETAPE 1 : ACQUISITION DES DONNEES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://atom-archives.unil.ch/index.php/aerny-francis', 'https://atom-archives.unil.ch/index.php/aleixandre-vicente', 'https://atom-archives.unil.ch/index.php/allini-pier', 'https://atom-archives.unil.ch/index.php/andres-stefan']\n",
      "['https://www.idref.fr/263915085.xml', 'https://www.idref.fr/026648261.xml', 'https://www.idref.fr/273130536.xml', 'https://www.idref.fr/072274670.xml']\n"
     ]
    }
   ],
   "source": [
    "def extract_autorite(csv_path, column_name_1) :\n",
    "    \"\"\"\n",
    "    Extrait les url de Phoebus des notices d'autorité ainsi que la Source (uri d'IdRef)\n",
    "\n",
    "    Args:\n",
    "        csv_path (str): Chemin vers le fichier CSV contenant les données.\n",
    "        column_name_1 (str): colonne à partir de laquelle extraire les urls de recherche sur Phoebus.\n",
    "        column_name_2 (str) : colonne à contenant l'uri d'IdRef\n",
    "\n",
    "    \"\"\"\n",
    "    # charger les données csv\n",
    "    df = pd.read_csv(csv_path, delimiter=',') #delimiter dépend de la configuration du separator du csv\n",
    "    # Extraire les noms de la colonne\n",
    "    names_to_extract = df[column_name_1].tolist()\n",
    "    return names_to_extract\n",
    "\n",
    "def extract_idRef(csv_path, column_name_2) :\n",
    "    \"\"\"\n",
    "    Extrait les url d'Idref des notices d'autorité et les modifie\n",
    "\n",
    "    Args:\n",
    "        csv_path (str): Chemin vers le fichier CSV contenant les données.\n",
    "        column_name_2 (str): Nom de la colonne à partir de laquelle extraire les noms.\n",
    "\n",
    "    Returns:\n",
    "        list: Liste des noms extraits de la colonne spécifiée.\n",
    "    \"\"\"\n",
    "    # charger les données csv\n",
    "    df = pd.read_csv(csv_path, delimiter=',') #delimiter dépend de la configuration du separator du csv\n",
    "    # Extraire les noms de la colonne\n",
    "    idRef_links = df[column_name_2].tolist()\n",
    "    \n",
    "    # Convertir les valeurs float en chaînes de caractères\n",
    "    idRef_links = [str(link) for link in idRef_links]\n",
    "    \n",
    "    idRef_links_xml = [link.replace('/id', '.xml') for link in idRef_links]    \n",
    "    return idRef_links_xml\n",
    "\n",
    "# LANCEMENT DE LA FONCTION\n",
    "csv_path = '01_autorite_Id.csv'\n",
    "column_name_1 = 'url_phoebus'\n",
    "column_name_2 = 'Sources'\n",
    "names_to_extract = extract_autorite(csv_path, column_name_1)\n",
    "idRef_links = extract_idRef(csv_path, column_name_2)\n",
    "\n",
    "# Afficher les noms (à titre de vérification)\n",
    "print(names_to_extract)\n",
    "print(idRef_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETAPE 2 : RECUPERATION DES DONNEES SUR IDREF AVEC GESTION DES ERREURS DUES AU TIME OUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['AERNY Francis', '19..-....', 'NULL', 'Professeur. ', 'Notice ABES. Date de création : 2022-08-23 - Date de modification : 2024-06-26 à 15:02:53.', \"Agence bibliographique de l'Enseignement supérieur (ABES) - Données originales récupérées sur http://www.idref.fr/263915085/id\", 'NULL', 'idref-263915085'], ['ALEIXANDRE Vicente', '1898-1984', 'NULL', 'Poète espagnol.', 'Notice ABES. Date de création : 1984-11-09 - Date de modification : 2024-06-26 à 15:00:55.', \"Agence bibliographique de l'Enseignement supérieur (ABES) - Données originales récupérées sur http://www.idref.fr/026648261/id\", 'ALEIXANDRE Y MERLO Vicente ; MERLO Vicente Aleixandre y.', 'idref-026648261'], ['ALLINI Pier', 's.d.', 'NULL', 'NULL', 'Notice ABES. Date de création : 2023-11-14 - Date de modification : 2024-06-26 à 15:02:03.', \"Agence bibliographique de l'Enseignement supérieur (ABES) - Données originales récupérées sur http://www.idref.fr/273130536/id\", 'NULL', 'idref-273130536'], ['ANDRES Stefan Paul', '1906-1970', 'NULL', 'Écrivain né en Allemagne et mort à Rome. ', 'Notice ABES. Date de création : 2003-06-17 - Date de modification : 2024-06-26 à 15:02:01.', \"Agence bibliographique de l'Enseignement supérieur (ABES) - Données originales récupérées sur http://www.idref.fr/072274670/id\", 'ANDRES Stefan.', 'idref-072274670']]\n"
     ]
    }
   ],
   "source": [
    "def extract_from_idRef(xml_urls, timeout_value):\n",
    "    \"\"\"\n",
    "    Extrait les données à partir d'une liste d'URLs pointant vers des enregistrements XML sur le service IDRef.\n",
    "\n",
    "    Args:\n",
    "        xml_urls (list): Liste d'URLs pointant vers des enregistrements XML sur IDRef.\n",
    "        timeout_value (int): Durée maximale lors de la tentative de connexion.\n",
    "\n",
    "    Returns:\n",
    "        list: Liste d'enregistrements extraits contenant les données récupérées depuis les enregistrements XML.\n",
    "              - 'ErrorTimeOut' : Erreur due à un dépassement du délai de connexion.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # GESTION DES TIME OUT ERROR : ESSAIS DE CONNEXION\n",
    "    # Configuration des tentatives de reconnexion\n",
    "    retries = Retry(total=3, backoff_factor=1, status_forcelist=[500, 502, 503, 504])\n",
    "    # Création d'un adaptateur avec les tentatives de reconnexion configurées\n",
    "    adapter = HTTPAdapter(max_retries=retries)\n",
    "    \n",
    "    \n",
    "    extracted_from_idRef = []\n",
    "    # Création d'une session avec l'adaptateur\n",
    "    with requests.Session() as session:\n",
    "        session.mount('https://', adapter)\n",
    "    \n",
    "        for i, xml_url in enumerate(xml_urls):\n",
    "\n",
    "            # Initialiser une liste pour cette notice\n",
    "            notice = []\n",
    "            # Initialiser les variables pour cet enregistrement\n",
    "            authorizedFormOfName = \"\"\n",
    "            nomAutorise = \"\"\n",
    "            prenomAutorise = \"\"\n",
    "            dateExistence = \"\"\n",
    "            functions = \"\"\n",
    "            infoPublique =\"\"\n",
    "            biographies = \"\"\n",
    "            history =\"\"\n",
    "            URI = \"\"\n",
    "            tous_AutresNomsPrenoms = \"\"\n",
    "            identifiant = \"\"\n",
    "\n",
    "            try :    \n",
    "                 # Récupérer le contenu XML depuis l'URL\n",
    "                response = session.get(xml_url, timeout = timeout_value)\n",
    "                response.raise_for_status()\n",
    "                xml_content = response.text\n",
    "                # Ajouter un délai entre les requêtes\n",
    "                time.sleep(5)\n",
    "\n",
    "                # Charger le contenu XML avec BeautifulSoup\n",
    "                soup = BeautifulSoup(xml_content, 'xml')\n",
    "\n",
    "                # FORME AUTORISEE DE NOM : Parcourir toutes les balises <datafield> avec les tags spécifiés (200)\n",
    "                tag200_datafields = soup.find('datafield', {'tag': ['200']})\n",
    "                if tag200_datafields :\n",
    "                    # Le tag 200 existe alors extraire le NOM, Prénom, les années d'existence\n",
    "                    nomAutorise = tag200_datafields.find('subfield', {'code': 'a'}).text if tag200_datafields.find('subfield', {'code': 'a'}) else ''\n",
    "                    prenomAutorise = tag200_datafields.find('subfield', {'code': 'b'}).text if tag200_datafields.find('subfield', {'code': 'b'}) else ''\n",
    "                    dateExistence = tag200_datafields.find('subfield', {'code': 'f'}).text if tag200_datafields.find('subfield', {'code': 'f'}) else 's.d.'\n",
    "                    functions = tag200_datafields.find('subfield', {'code': 'c'}).text if tag200_datafields.find('subfield', {'code': 'c'}) else 'NULL'\n",
    "\n",
    "                    # Mettre en forme les noms autorisées\n",
    "                    nomAutorise = nomAutorise.upper()\n",
    "                    # Concaténer les valeurs du nom autorisé\n",
    "                    authorizedFormOfName = f'{nomAutorise} {prenomAutorise}'\n",
    "                else:\n",
    "                    # Le tag 200 n'existe pas\n",
    "                    nomAutorise = \"NULL\"\n",
    "                    prenomAutorise = \"NULL\"\n",
    "                    dateExistence = \"NULL\"\n",
    "                    functions = \"NULL\"\n",
    "                    \n",
    "                # Note publique d'information\n",
    "                tag300_datafields = soup.find_all('datafield', {'tag':'300'})\n",
    "\n",
    "                if tag300_datafields:\n",
    "                    for tag300_datafield in tag300_datafields :\n",
    "                        infoPublique = tag300_datafield.find('subfield', {'code': 'a'}).text if tag300_datafield.find('subfield', {'code': 'a'}) else ''\n",
    "                else :\n",
    "                    infoPublique = \"NULL\"\n",
    "                        \n",
    "                # Ajouter un point à la fin\n",
    "                infoPublique += f\".\"\n",
    "                # Supprimer les doubles espaces\n",
    "                infoPublique = infoPublique.replace(\"  \",\" \")\n",
    "                # Remplacer \" ; .\" par \".\" pour terminer la liste\n",
    "                infoPublique = infoPublique.replace(\" ; .\",\".\")\n",
    "                # Remplacer \"NULL.\" par \"NULL\" pour uniformiser toutes les valeurs NULL\n",
    "                infoPublique = infoPublique.replace(\"NULL.\",\"NULL\")\n",
    "                # supprimer les espaces avant et à la fin\n",
    "                infoPublique = infoPublique.strip()        \n",
    "\n",
    "                # HISTORIQUE : Parcourir toutes les balises <datafield> avec les tags spécifiés (340)\n",
    "                tag340_datafields = soup.find_all('datafield', {'tag':'340'})\n",
    "\n",
    "                if tag340_datafields:\n",
    "                    for tag340_datafield in tag340_datafields :\n",
    "                        biographie = tag340_datafield.find('subfield', {'code': 'a'}).text if tag340_datafield.find('subfield', {'code': 'a'}) else ''\n",
    "                        biographie = f\"{biographie} ; \"\n",
    "                        biographies += biographie\n",
    "                else:\n",
    "                # Si aucune biographie trouvée, définir comme \"NULL\"\n",
    "                    biographies =\"NULL\"\n",
    "\n",
    "                # Ajouter un point à la fin\n",
    "                biographies += f\".\"\n",
    "                # Supprimer les doubles espaces\n",
    "                biographies = biographies.replace(\"  \",\" \")\n",
    "                # Remplacer \" ; .\" par \".\" pour terminer la liste\n",
    "                biographies = biographies.replace(\" ; .\",\".\")\n",
    "                # Remplacer \"NULL.\" par \"NULL\" pour uniformiser toutes les valeurs NULL\n",
    "                biographies = biographies.replace(\"NULL.\",\"NULL\")\n",
    "                # supprimer les espaces avant et à la fin\n",
    "                biographies = biographies.strip()\n",
    "\n",
    "                #Mise en forme history en corrigeant la concaténation de biographies et infoPublique\n",
    "                history = f\"{biographies} ; {infoPublique}\"\n",
    "                history = history.replace(\"..\",\".\")\n",
    "                history = history.replace(\"NULL ; NULL\",\"NULL\")\n",
    "                history = history.replace(\"NULL ; \",\"\")\n",
    "                history = history.replace(\"; NULL\",\"\")\n",
    "\n",
    "                 # SOURCES : Extraire le lien URI\n",
    "                URI = soup.find('controlfield', {'tag': '003'}).text if soup.find('controlfield', {'tag': '003'}) else ''\n",
    "                # DATE DE CREATION de la notice : \n",
    "                creationDate = soup.find('controlfield', {'tag': '004'}).text if soup.find('controlfield', {'tag': '004'}) else ''\n",
    "                # DATE DE MODIFICATION de la notice : \n",
    "                modificationDate = soup.find('controlfield', {'tag': '005'}).text if soup.find('controlfield', {'tag': '005'}) else ''\n",
    "\n",
    "                #METTRE EN FORME URI, Dates de création et de modification)\n",
    "                URI = URI + \"/id\"\n",
    "                # Formater la date de création\n",
    "                creationDate = datetime.strptime(creationDate, \"%Y%m%d\").strftime(\"%Y-%m-%d\")\n",
    "                # Formater la date de modification\n",
    "                modificationDate = datetime.strptime(modificationDate, \"%Y%m%d%H%M%S.%f\").strftime(\"%Y-%m-%d à %H:%M:%S\")\n",
    "                #METTRE EN FORME LE CHAMP SOURCE\n",
    "                referenceIdRef = f\"Agence bibliographique de l'Enseignement supérieur (ABES) - Données originales récupérées sur {URI}\"\n",
    "                #METTRE EN FORME LE CHAMP DATES DE PROD, REVISION\n",
    "                revisionHistory = f\"Notice ABES. Date de création : {creationDate} - Date de modification : {modificationDate}.\"\n",
    "\n",
    "                # AUTRES FORMES DE NOM : Parcourir TOUTES les balises <datafield> avec le tag \"400\" //dans la structure XML, il y en a plusieurs \n",
    "                tag400_datafields = soup.find_all('datafield', {'tag': ['400']})\n",
    "                if tag400_datafields :\n",
    "                    # Au moins une occurrence du tag 400 existe\n",
    "                    for tag400_datafield in tag400_datafields :\n",
    "                        # Extraire les sous-champs 'a' et 'b'\n",
    "                        autreNom = tag400_datafield.find('subfield', {'code': 'a'}).text if tag400_datafield.find('subfield', {'code': 'a'}) else ''\n",
    "                        autrePrenom = tag400_datafield.find('subfield', {'code': 'b'}).text if tag400_datafield.find('subfield', {'code': 'b'}) else ''\n",
    "\n",
    "                        # Mettre en forme et concaténer les autres Noms\n",
    "                        autreNom = autreNom.upper()\n",
    "                        autresNomsPrenoms = f\"{autreNom} {autrePrenom} ; \"\n",
    "                        # Concaténer les valeurs des noms alternatifs\n",
    "                        tous_AutresNomsPrenoms += autresNomsPrenoms\n",
    "                else:\n",
    "                    # Le tag 400 n'existe pas\n",
    "                    tous_AutresNomsPrenoms = \"NULL\"\n",
    "\n",
    "                # Ajouter un point à la fin\n",
    "                tous_AutresNomsPrenoms += f\".\"\n",
    "                # Supprimer les doubles espaces\n",
    "                tous_AutresNomsPrenoms = tous_AutresNomsPrenoms.replace(\"  \",\" \")\n",
    "                # Remplacer \" ; .\" par \".\" pour terminer la liste des autres formes de nom\n",
    "                tous_AutresNomsPrenoms = tous_AutresNomsPrenoms.replace(\" ; .\",\".\")\n",
    "                # Remplacer \"NULL.\" par \"NULL\" pour uniformiser toutes les valeurs NULL\n",
    "                tous_AutresNomsPrenoms = tous_AutresNomsPrenoms.replace(\"NULL.\",\"NULL\")\n",
    "                # supprimer les espaces avant et à la fin\n",
    "                tous_AutresNomsPrenoms = tous_AutresNomsPrenoms.strip()\n",
    "                \n",
    "                # IDENTIFIANTS : prendre l'identifiant idref\n",
    "                identifiant = soup.find('controlfield', {'tag': '001'}).text if soup.find('controlfield', {'tag': '003'}) else 'ERROR'\n",
    "                identifiant = \"idref-\"+identifiant\n",
    "                \n",
    "\n",
    "                # Ajouter les données (si données existent ou non) à la liste \"notice\"\n",
    "                notice.append(authorizedFormOfName)\n",
    "                notice.append(dateExistence)\n",
    "                notice.append(functions)\n",
    "                notice.append(history)\n",
    "                notice.append(revisionHistory)\n",
    "                notice.append(referenceIdRef)\n",
    "                notice.append(tous_AutresNomsPrenoms)\n",
    "                notice.append(identifiant)\n",
    "\n",
    "                # Ajouter l'enregistrement à la liste principale\n",
    "                extracted_from_idRef.append(notice)\n",
    "\n",
    "            # GESTION DES ERREURS DU AU TIME OUT    \n",
    "            except (requests.Timeout, requests.RequestException) as e:\n",
    "                notice.extend([\"ErrorTimeOut\"]*5)\n",
    "                notice.append(xml_url)\n",
    "                notice.append(\"ErrorTimeOut\")\n",
    "                # Ajouter l'enregistrement à la liste principale\n",
    "                extracted_from_idRef.append(notice)\n",
    "                print(f\"Erreur de time out lors de la requête pour {names[i]} : {xml_url}\")\n",
    "                print(f\"Exception : {e}\")\n",
    "\n",
    "            #except Exception as e:\n",
    "                print(f\"Erreur non gérée lors de la requête pour {names[i]} : {xml_url}. Erreur : {type(e).__name__}\")\n",
    "\n",
    "\n",
    "    return extracted_from_idRef\n",
    "            \n",
    "\n",
    "# LANCEMENT DE LA FONCTION\n",
    "xml_urls = idRef_links\n",
    "names = names_to_extract\n",
    "timeout_value = 10 # détermine la durée maximale lors de la tentative de connexion.\n",
    "extracted_from_idRef = extract_from_idRef(xml_urls, timeout_value)\n",
    "\n",
    "print(extracted_from_idRef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETAPE 3 : MISE EN FORME DES DONNEES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['https://atom-archives.unil.ch/index.php/aerny-francis', 'AERNY Francis', '19..-....', 'NULL', 'Professeur. ', 'Notice ABES. Date de création : 2022-08-23 - Date de modification : 2024-06-26 à 15:02:53.', \"Agence bibliographique de l'Enseignement supérieur (ABES) - Données originales récupérées sur http://www.idref.fr/263915085/id\", 'NULL', 'aerny-francis_idref-263915085'], ['https://atom-archives.unil.ch/index.php/aleixandre-vicente', 'ALEIXANDRE Vicente', '1898-1984', 'NULL', 'Poète espagnol.', 'Notice ABES. Date de création : 1984-11-09 - Date de modification : 2024-06-26 à 15:00:55.', \"Agence bibliographique de l'Enseignement supérieur (ABES) - Données originales récupérées sur http://www.idref.fr/026648261/id\", 'ALEIXANDRE Y MERLO Vicente ; MERLO Vicente Aleixandre y.', 'aleixandre-vicente_idref-026648261'], ['https://atom-archives.unil.ch/index.php/allini-pier', 'ALLINI Pier', 's.d.', 'NULL', 'NULL', 'Notice ABES. Date de création : 2023-11-14 - Date de modification : 2024-06-26 à 15:02:03.', \"Agence bibliographique de l'Enseignement supérieur (ABES) - Données originales récupérées sur http://www.idref.fr/273130536/id\", 'NULL', 'allini-pier_idref-273130536'], ['https://atom-archives.unil.ch/index.php/andres-stefan', 'ANDRES Stefan Paul', '1906-1970', 'NULL', 'Écrivain né en Allemagne et mort à Rome. ', 'Notice ABES. Date de création : 2003-06-17 - Date de modification : 2024-06-26 à 15:02:01.', \"Agence bibliographique de l'Enseignement supérieur (ABES) - Données originales récupérées sur http://www.idref.fr/072274670/id\", 'ANDRES Stefan.', 'andres-stefan_idref-072274670']]\n"
     ]
    }
   ],
   "source": [
    "def format_data(list1, list2):\n",
    "    \"\"\"\n",
    "    Combinaison de deux listes en une liste de listes.\n",
    "\n",
    "    Args:\n",
    "        list1 (list): Liste contenant les urls tirés de Phoebus à utiliser comme premiers éléments de chaque sous-liste.\n",
    "        list2 (list): Liste contenant les données récupérées d'IDRef à utiliser comme éléments suivants de chaque sous-liste.\n",
    "\n",
    "    Returns:\n",
    "        list: Liste de listes où chaque sous-liste commence par un élément de list1 suivi des éléments correspondants de list2.\n",
    "\n",
    "    \"\"\"\n",
    "    # Reformater les données en une liste de listes\n",
    "    formatted_data = []\n",
    "\n",
    "    for name, idRef_info in zip(list1, list2):\n",
    "                \n",
    "        #Modifier l'identifiant en ajoutant l'url \n",
    "        url_parts = name.split(\"/\")\n",
    "        identifier = url_parts[-1]  # Récupérer la dernière partie de l'URL\n",
    "        \n",
    "        idRef_info[-1] = identifier + \"_\" + idRef_info[-1]\n",
    "        formatted_data.append([name] + idRef_info)\n",
    "\n",
    "    return formatted_data\n",
    "\n",
    "# LANCEMENT DE LA FONCTION\n",
    "# Données à écrire dans le csv\n",
    "list1 = names_to_extract\n",
    "list2 = extracted_from_idRef\n",
    "formatted_data = format_data(list1, list2)\n",
    "print(formatted_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETAPE 4 : ECRITURE DES DONNEES DANS LE FICHIER CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_csv(csv_filename, headers, formatted_data) :\n",
    "    \"\"\"\n",
    "    Écrit les données dans un fichier CSV.\n",
    "\n",
    "    Args:\n",
    "        csv_filename (str): Nom du fichier CSV à créer ou mettre à jour.\n",
    "        headers (list): Liste des en-têtes de colonnes pour le fichier CSV.\n",
    "        formatted_data (list): Liste de listes contenant les données à écrire dans le fichier CSV.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"    \n",
    "    # Écriture dans le fichier CSV\n",
    "    with open(csv_filename, mode='w', newline='', encoding='utf-8') as csv_file:\n",
    "        csv_writer = csv.writer(csv_file, delimiter=',')\n",
    "\n",
    "         # Écrire l'en-tête du CSV\n",
    "        csv_writer.writerow(headers)\n",
    "        \n",
    "        # Écrire les données dans le fichier CSV\n",
    "        csv_writer.writerows(formatted_data)\n",
    "\n",
    "# LANCEMENT DE LA FONCTION\n",
    "csv_filename = '02_resultats.csv'\n",
    "headers = ['url_phoebus', 'Forme autorisée de nom', 'DateExistence', 'Activités','Historique', 'Historique de révision','Sources', 'Autre(s) forme(s) du nom','Identifiant']\n",
    "\n",
    "write_to_csv(csv_filename, headers, formatted_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LANCEMENT DES FONCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETAPE 1\n",
    "csv_path = '01_autorite_Id.csv'\n",
    "column_name_1 = 'url_phoebus'\n",
    "column_name_2 = 'Sources'\n",
    "names_to_extract = extract_autorite(csv_path, column_name_1)\n",
    "idRef_links = extract_idRef(csv_path, column_name_2)\n",
    "\n",
    "# ETAPE 2\n",
    "xml_urls = idRef_links\n",
    "names = names_to_extract\n",
    "timeout_value = 10 # détermine la durée maximale lors de la tentative de connexion.\n",
    "extracted_from_idRef = extract_from_idRef(xml_urls, timeout_value)\n",
    "\n",
    "# ETAPE 3\n",
    "list1 = names_to_extract\n",
    "list2 = extracted_from_idRef\n",
    "formatted_data = format_data(list1, list2)\n",
    "\n",
    "# ETAPE 4\n",
    "csv_filename = '02_resultats.csv'\n",
    "headers = ['url_phoebus', 'Forme autorisée de nom', 'DateExistence', 'Activités','Historique', 'Historique de révision','Sources', 'Autre(s) forme(s) du nom','Identifiant']\n",
    "write_to_csv(csv_filename, headers, formatted_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
